{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Files with No Duplicates\n",
    "\n",
    "The goal of this notebook is to have two modes, such that two folders can be merged without duplicates:\n",
    "\n",
    "1. Mark only mode: Given a directory, hash each file using MD5 and file size\n",
    "2. Copy mode: Copy each file not in the hash table to another directory\n",
    "\n",
    "This requires creating four pieces of functionality:\n",
    "\n",
    "1. Serializing and deserializing a Python dict containing the data (hash plus size)\n",
    "2. Being able to iterate through files\n",
    "3. Being able to hash the file in question and extract its size\n",
    "4. Being able to copy files from one directory to another while maintaining their relative directory structure\n",
    "\n",
    "## Sources\n",
    "\n",
    "* D:\\Dropbox\\Project Hub\\Website\\KieferFlaskSite\\home\\scripts\\file_age_directory.py\n",
    "* https://stackoverflow.com/questions/8858008/how-to-move-a-file-in-python#8858026\n",
    "* https://stackoverflow.com/questions/1072569/see-if-two-files-have-the-same-content-in-python\n",
    "* https://stackoverflow.com/questions/5787471/md5-and-sha-2-collisions-in-python\n",
    "* https://stackoverflow.com/questions/3431825/generating-an-md5-checksum-of-a-file\n",
    "* https://stackoverflow.com/questions/6773584/how-is-pythons-glob-glob-ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing and Deserializing the Hash Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hash_table(hash_table_path: str) -> dict:\n",
    "    \"\"\"Loads a hash table dict from a file.\"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(hash_table_path, 'r') as f_json:\n",
    "            return json.load(f_json)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def save_hash_table(hash_table_path: str, hash_table: dict):\n",
    "    \"\"\"Loads a hash table dict from a file.\"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(hash_table_path, 'w') as f_json:\n",
    "            json.dump(hash_table, f_json, indent=4, sort_keys=True)\n",
    "    except FileNotFoundError:\n",
    "        print('Could not create json file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_md5(file_path: str) -> str:\n",
    "    \"\"\"Create an MD5 hash of a file's contents.\"\"\"\n",
    "    \n",
    "    hash_md5 = hashlib.md5()\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f_to_hash:\n",
    "            for chunk in iter(lambda: f_to_hash.read(4096), b''):\n",
    "                hash_md5.update(chunk)\n",
    "    except FileNotFoundError:\n",
    "        return 'BADHASH'\n",
    "    \n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "\n",
    "def hash_file(hash_table: dict, file_path_object) -> bool:\n",
    "    \"\"\"Attempt to hash a file and return true iff it was not already hashed.\"\"\"\n",
    "\n",
    "    file_path = str(file_path_object)\n",
    "    file_size = str(os.path.getsize(file_path))\n",
    "    file_name = file_path_object.name\n",
    "    file_hash = create_md5(file_path)\n",
    "    combined_hash = f'{file_hash}{file_size}'\n",
    "    \n",
    "    if combined_hash in hash_table:\n",
    "        if file_name not in hash_table[combined_hash]['names']:\n",
    "            hash_table[combined_hash]['names'].append(file_name)\n",
    "        return False\n",
    "    else:\n",
    "        hash_table[combined_hash] = {\n",
    "            'md5': file_hash,\n",
    "            'size': file_size,\n",
    "            'names': [file_name]\n",
    "        }\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files_relative(old_dir_path: str, new_dir_path: str, file_path: str):\n",
    "    \"\"\"Moves a file from one directory to another, keeping its relative file structure.\"\"\"\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        relative_path = file_path.replace(old_dir_path, \"\")\n",
    "        new_path = f'{new_dir_path}{relative_path}'\n",
    "        os.makedirs(os.sep.join(new_path.split(os.sep)[:-1]), exist_ok=True)\n",
    "        shutil.copyfile(file_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating Through Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earliest_age(file_path_object) -> int:\n",
    "    \"\"\"Returns the earliest of created and modified time for a file path object.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        return min(\n",
    "            os.path.getmtime(str(file_path_object)),\n",
    "            os.path.getctime(str(file_path_object))\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_files_in_directory(hash_table: dict, dir_path: str):\n",
    "    \"\"\"Hashes all files in a directory.\"\"\"\n",
    "    \n",
    "    hashed = 0\n",
    "    duplicate = 0\n",
    "    \n",
    "    file_paths = sorted(Path(dir_path).glob('**/*'), key=get_earliest_age)\n",
    "    for file_path in file_paths:\n",
    "        if os.path.isdir(str(file_path)):\n",
    "            continue\n",
    "        \n",
    "        if hash_file(hash_table, file_path):\n",
    "            hashed += 1\n",
    "            print(f'Hashed: {file_path}')\n",
    "        else:\n",
    "            duplicate += 1\n",
    "            print(f'Hashed, Duplicate: {file_path}')\n",
    "    \n",
    "    print(f'\\n{hashed + duplicate} total files, {hashed} new hashes, {duplicate} duplicates')\n",
    "\n",
    "\n",
    "def hash_and_copy_files_in_directory(hash_table: dict, old_dir_path: str, new_dir_path: str):\n",
    "    \"\"\"Hashes all files in a directory.\"\"\"\n",
    "    \n",
    "    hashed = 0\n",
    "    duplicate = 0\n",
    "    failures = []\n",
    "    \n",
    "    file_paths = sorted(Path(old_dir_path).glob('**/*'), key=get_earliest_age)\n",
    "    for file_path in file_paths:\n",
    "        if os.path.isdir(str(file_path)):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            if hash_file(hash_table, file_path):\n",
    "                move_files_relative(old_dir_path, new_dir_path, str(file_path))\n",
    "                print(f'Hashed, Moved: {file_path}')\n",
    "                hashed += 1\n",
    "            else:\n",
    "                print(f'Hashed, Duplicate: {file_path}')\n",
    "                duplicate += 1\n",
    "        except FileNotFoundError:\n",
    "            print(f'FAILED: {file_path}')\n",
    "            failures.append(str(file_path))\n",
    "    \n",
    "    fail_count = len(failures)\n",
    "    print(f'\\n{hashed + duplicate + fail_count} total files, {hashed} moved, {duplicate} duplicates')\n",
    "    if failures:\n",
    "        print(f'\\n{fail_count} files failed:')\n",
    "        for fail in failures:\n",
    "            print(f'* {fail}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_files():\n",
    "    \"\"\"Add files in a directory to a hash table.\"\"\"\n",
    "    \n",
    "    hash_table_file = input('Hash table file: ')\n",
    "    source_directory = input('Source directory: ')\n",
    "    \n",
    "    print('\\nProcessing...\\n')\n",
    "    \n",
    "    hash_table = load_hash_table(hash_table_file)\n",
    "    hash_files_in_directory(hash_table, source_directory)\n",
    "    save_hash_table(hash_table_file, hash_table)\n",
    "    \n",
    "    print('\\nDone!')\n",
    "\n",
    "\n",
    "def copy_files():\n",
    "    \"\"\"Hash and copy unhashed files in a directory to another folder.\"\"\"\n",
    "\n",
    "    hash_table_file = input('Hash table file: ')\n",
    "    source_directory = input('Source directory: ')\n",
    "    destination_directory = input('Destination directory: ')\n",
    "    \n",
    "    print('\\nProcessing...\\n')\n",
    "    \n",
    "    hash_table = load_hash_table(hash_table_file)\n",
    "    hash_and_copy_files_in_directory(hash_table, source_directory, destination_directory)\n",
    "    save_hash_table(hash_table_file, hash_table)\n",
    "    \n",
    "    print('\\nDone!')\n",
    "\n",
    "    \n",
    "def main():\n",
    "    print('Copy files with no duplicates!  Please do not use relative file paths and do not include trailing slashes.')\n",
    "    mode = input('Mode (MARK, COPY, DEBUG): ')\n",
    "    print('')\n",
    "    if mode.lower() == 'mark':\n",
    "        confirm = input('Are you sure you want to do MARK mode, and not COPY? ')\n",
    "        if confirm.lower() == 'yes':\n",
    "            mark_files()\n",
    "    elif mode.lower() == 'copy':\n",
    "        copy_files()\n",
    "    else:\n",
    "        debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example directories:\n",
    "\n",
    "```\n",
    "D:\\Dropbox\\Project Hub\\Game_and_Programming_Tutorials\\Python File Manipulation\\Armistice_HT.json\n",
    "D:\\Dropbox\\Project Hub\\Game_and_Programming_Tutorials\\Python File Manipulation\\Armistice\n",
    "D:\\Dropbox\\Project Hub\\Game_and_Programming_Tutorials\\Python File Manipulation\\Armistice_New\n",
    "\n",
    "phone_backups.json\n",
    "D:\\Media\\Phone Backups\\LG G5\n",
    "C:\\Media\\Phone Backups Temp\\Deduplicated Phone Backups\\LG G5\n",
    "D:\\Media\\Phone Backups\\From 32 GB SD Card\n",
    "C:\\Media\\Phone Backups Temp\\Note 9 2022-02-06\n",
    "D:\\Media\\Phone Backups\\Note 9\\From SD Card 2020-11-09\n",
    "C:\\Media\\Straggler Files 2021-03-27\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def debug():\n",
    "    return False\n",
    "\n",
    "    print('hello worlds')\n",
    "    old_dir_path = input('Source directory: ')\n",
    "    new_dir_path = input('Destination directory: ')\n",
    "    \n",
    "    file_paths = Path(old_dir_path).glob('**/*')\n",
    "    for file_path in file_paths:\n",
    "        file_path = str(file_path)\n",
    "        print(file_path)\n",
    "        if os.path.isfile(file_path):\n",
    "            relative_path = file_path.replace(old_dir_path, \"\")\n",
    "            new_path = f'{new_dir_path}{relative_path}'\n",
    "            os.makedirs(os.sep.join(new_path.split(os.sep)[:-1]), exist_ok=True)\n",
    "            shutil.copyfile(file_path, new_path)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
